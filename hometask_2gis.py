# -*- coding: utf-8 -*-
"""Leetcode_note.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RHM853N1v7aPl-ozuSdVmodZzkR8QlB3

Задание:

Есть датасет. Собран он следующим образом:

Из логов были взяты пары ([запрос] - [объект на который кликнул пользователь]). Это положительные примеры (метка 1 в датасете)
Для каждого запроса был подобран в пару негативный объект (метка 0) следующим образом: определяем к какой рубрике относится положительный пример; выбираем случайный объект из другой рубрики. Идея в том, что этот пример маловероятно будет релевантным.
На этих данных, используя кросс-валидацию, обучались различные модели. Метрики качества были хорошими. При попытки тестирования на реальных данных, качество моделей сильно уступало тестовым метрикам.

Задача: выявить особенности датасета, которые приводили к данным результатам и объяснить почему так происходило.


---



Отчет описан в файле **report.pdf** и **report.md**
"""

from sklearn.model_selection import cross_validate, TimeSeriesSplit
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostClassifier
from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
import pandas as pd
import numpy as np

path_dataset = '/content/clicks_dataset_msk_20230101_20230725_spec.csv'

df = pd.read_csv(path_dataset, names=['query_id','object_id', 'target'], nrows=1000000)

df.head()

# Преобразование типов данных
df['query_id'] = df['query_id'].astype('int32')
df['object_id'] = df['object_id'].astype('int32')
df['target'] = df['target'].astype('int8')

df.info()

# Распределение целевой переменной
df['target'].value_counts()

# Всего рубрик
df['object_id'].nunique()

# Распределение рубрик
df['object_id'].value_counts()

"""### Расчет метрик для среза датасета в 1 млн строк"""

# Разделение на признаки и целевую переменную
X = df.drop('target', axis=1)
y = df['target']

# Создание моделей
rf_model = RandomForestClassifier(n_estimators=100)
xgb_model = xgb.XGBClassifier(n_estimators=100)
catboost_model = CatBoostClassifier(n_estimators=100, verbose=False)
lgb_model = lgb.LGBMClassifier(n_estimators=100)

# Метрики для оценки моделей
scoring_metrics = {
    'f1': make_scorer(f1_score),
    'roc_auc': make_scorer(roc_auc_score)
}

tscv = TimeSeriesSplit(n_splits=5)

# Оценка моделей с кросс-валидацией
rf_cv_results = cross_validate(rf_model, X, y, cv=tscv, scoring=scoring_metrics)
xgb_cv_results = cross_validate(xgb_model, X, y, cv=tscv, scoring=scoring_metrics)
catboost_cv_results = cross_validate(catboost_model, X, y, cv=tscv, scoring=scoring_metrics)
lgb_cv_results = cross_validate(lgb_model, X, y, cv=tscv, scoring=scoring_metrics)

"""#### Вывод результатов"""

print("RandomForest:")
for metric, values in rf_cv_results.items():
    if metric != 'fit_time' and metric != 'score_time':
        print(f"{metric}: Mean {np.mean(values):.4f}")

print("XGBoost:")
for metric, values in xgb_cv_results.items():
    if metric != 'fit_time' and metric != 'score_time':
        print(f"{metric}: Mean {np.mean(values):.4f}")

print("CatBoost:")
for metric, values in catboost_cv_results.items():
    if metric != 'fit_time' and metric != 'score_time':
        print(f"{metric}: Mean {np.mean(values):.4f}")

print("LightGBM:")
for metric, values in lgb_cv_results.items():
    if metric != 'fit_time' and metric != 'score_time':
        print(f"{metric}: Mean {np.mean(values):.4f}")

"""### Расчет метрик для всего датасета"""

full_df = pd.read_csv(path_dataset, names=['query_id','object_id', 'target'])

# Преобразование типов данных
full_df['query_id'] = full_df['query_id'].astype('int32')
full_df['object_id'] = full_df['object_id'].astype('int32')
full_df['target'] = full_df['target'].astype('int8')

# Разделение на признаки и целевую переменную
X_full = full_df.drop('target', axis=1)
y_full = full_df['target']

# Оценка моделей с кросс-валидацией
xgb_cv_results_full = cross_validate(xgb_model, X_full, y_full, cv=tscv, scoring=scoring_metrics)
catboost_cv_results_full = cross_validate(catboost_model, X_full, y_full, cv=tscv, scoring=scoring_metrics)
lgb_cv_results_full = cross_validate(lgb_model, X_full, y_full, cv=tscv, scoring=scoring_metrics)

"""#### Выввод результатов"""

print("XGBoost:")
for metric, values in xgb_cv_results_full.items():
    if metric != 'fit_time' and metric != 'score_time':
        print(f"{metric}: Mean {np.mean(values):.4f}")

print("CatBoost:")
for metric, values in catboost_cv_results_full.items():
    if metric != 'fit_time' and metric != 'score_time':
        print(f"{metric}: Mean {np.mean(values):.4f}")

print("LightGBM:")
for metric, values in lgb_cv_results_full.items():
    if metric != 'fit_time' and metric != 'score_time':
        print(f"{metric}: Mean {np.mean(values):.4f}")

"""### Пример датасета, который должен и на обучении, и на тестировании на реальных данных показывать хорошие результаты"""

feature_df = pd.read_csv(path_dataset, names=['query_id','object_id', 'target'], nrows=100)

# Количество дополнительных записей с target 0
additional_records = 8

for i in feature_df['query_id'].unique():
    additional_data = {
        'query_id': i,
        'object_id': np.random.choice(df['object_id'], additional_records),
        'target': np.zeros(additional_records)
    }

    additional_df = pd.DataFrame(additional_data)
    feature_df = pd.concat([feature_df, additional_df], ignore_index=True)

"""*Возьмем для пример query_id = 1590973*"""

feature_df[feature_df['query_id'] == 1590973]

